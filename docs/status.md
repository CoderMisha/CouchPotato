---
layout: default
title: Status
---

# Couch Potato

Insert video

## Project Summary

We intent to build a environment description system for this project which enable users to ask questions to our Malmo agent and then get the answer back through the terminal. Our system accepts multiple ways of asking, including the entity itself, its position and its quantity. All of those scenario information will be obtained from the Malmo APL, so that we could compute the target results based on the raw world state information. To understand different expressions for the same way of asking, we use NLP tools for input parsing and syntax analysis. Our goal is to extract keywords which could match to our action functions.

## Approach

Our projects mainly includes two stages: (1) Generating observation results and (2) Understanding user inputs in different expressions.
<br>(1) All of the results to the user input questions are generated by our system background using Malmo build-in function: **agent.peekWorldState()**. After we convert the result into redable json text, we can get all the current positions and quantities of different entities based on our map coordinate system. By using the distance formula, we could get the distance of one enity to another entity or the distance of one entity to where our agent standing. Therefore, from a given location (e.g. agent's current location) and a given / default range, we could get the quantities for each existing entities asked by the user. For more detailed position describing and environment describing, all of the coordinates of our static architects (house, lake, trees, etc.) are saved as global variables.

<br>Calculating position (left, right, behind, front, etc.) for one entity relative to a static architect is simple by just comparing their x and y coordinates. However, when calculating positions of entity relative to the agent, we need to include the direction of where agent face to get the result of whether this entity is standing on the left side, right side, front or behind the agent. The attribute of this facing direction is represented as "Yaw" in degress for our agent in the world state (Figure 1); since this degree is relative to the (0,0) point of our map, we've also calculate the dergree of where the target entity standing relative to the zero point. By comparing the difference between these two degrees, we could get our result position.

<p><img src="assets/position_calc.png" width="650" alt/><em>Figure 1: Position calculation</em></p>

## Evaluation

Evaluating our project is quite manually as we could only check the correctness of outcome based how our agent's understanding similar to human understanding.

## Remaining Goals and Challenges
